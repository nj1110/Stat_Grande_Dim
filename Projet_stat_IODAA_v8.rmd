---
title: "Projet_stat_IODAA"
authors: "Anne-Cécile TOULEMONDE,Nora PICAUT,Noémie JACQUET"
date: "2023-01-20"
output:
  beamer_presentation: default
  powerpoint_presentation: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

## Préparartion de l'espace de travail 

#### Espace de  travail 
```{r}
setwd("~/IODAA/Cours_IODAA/STAT-GRANDE-DIM/PROJET/Data")
```

#### Installation des packages 

```{r}
install.packages("contrib.url")
install.packages("FactoMinerR")
install.packages("corrplot")
install.packages("factoextra")
install.packages("VIM")
```

```{r cars}
library(readr)
library(tidyverse)
library(corrplot)
library(FactoMineR)
library(factoextra)
library(ggplot2)
library("VIM")
library(glmnet)
```

#### Importation des données 

```{r pressure, echo=FALSE}
df = read.csv2("Table_proteome_CD_all.csv")
```

## Objectifs du projet
Etude de l'influence de la température et du stade d'imbibition sur la capacité germinative des graines à l'aide de données de protéomique pour des graines ayant subi un vieillissement artificiel immédiat (CD_0d).

**Descripteurs:** 
- température (variable qualitative à 3 modalités : *Low*, *Medium* et *Elevated*
- stade d'imbibition (variable qualitative à 3 modalités :*DS* , *EI* , *LI*

**Variable à prédire** : (variable qualitative) Capacité germinative des graines à l'aide de données de protéomique
pour des graines ayant subi un vieillissement artificiel immédiat (CD_0d).

## QUESTION 1 Analyse descriptive 
### Nombre de lignes et colonnes 
```{r}
dim(df)
```

### Apercu du jeu de données 
```{r}
head(df)
```
#### Liste des variables 
```{r}
names(df) # Liste des variables 
```
#### Type des variables 

```{r}
str(df) ## Type de colonnes 
```

#### Dispersion des variables 
Informations descriptives 
```{r}
#summary(df) 
```

### Anlayse des corrélations (variables quantitatives)
Matrice de corrélation à partor de la 7eme colonne du dataset 
```{r}
library(corrplot)
df1=df[df$treatment=="CD_0d", c(7:length(df))]
head(df1)
corrplot(cor(df1))
```

### Analyse à composantes principales 
### l'ACP n'est pas suffisante: il faut attendre le 5e axe pour expliquer 70% de la variance cumulée.
### PAS TRES INTERPRETABLE L'ACP sur les protéines donc on doit faire de la sélection de variable
```{r}
res.pca = PCA(df1,graph = FALSE)
get_eigenvalue(res.pca)
fviz_pca_var(res.pca,axes=1:2)
fviz_pca_ind(res.pca,axes=1:2)
fviz_pca_var(res.pca, axes = c(1:3))
```


#### Prétraitement 
Nombre de valeurs manquantes 
```{r}
res = summary(aggr(df,sortVar = TRUE))$group
matrixplot(df,sortby = 2 )
```
Il n'y a pas de valeurs manquantes dans ce jeu de données. 

###  Analyse descriptive : HEATMAP de correlation entre les métabolites 
### on fait une heatmap des protéines pour voir si corrélées entre elles, justement on verra rien meme en acp etc d'ou la necessité de faire de la selection de variables. Plus c'est rouge plus il y a de corrélation: groupe de protéines en bas à droite corrélées entre elles, mais il y en a bcp on doit aller plus loin et faire de la sélection de variables
```{r}
head(df1)
heatmap(abs(cor(df1)), symm=TRUE)

```


### QUESTION 2 - ANOVA 1 facteur (temperature) 

### ETAPE : MATRICE DE DESIGN
On construit la matrice de design 
```{r}
install.packages("MultiVarSel")
library(MultiVarSel)
df2= df[df$treatment=="CD_0d", c(4,7:length(df))]
rownames(df2) <- NULL
head(df2)
X_df2=df2[, 1]
X_df2 <- factor(as.character(X_df2))
Y_2 <- as.matrix(df2[,2:length(df2)])
Y_2 <- scale(Y_2)
X2 <- model.matrix(lm(Y_2~ X_df2 + 0))
head(X2)


#Dimensions n, p,q
n=nrow(X2)
n
p=ncol(X2)
p
q=dim(Y_2)[2]
q

```


## ETAPE : tester si les colonnes des résidus sont independantes avec le test du Portmanteau test
voir si les colonnes de Y sont indépendantes - estimer les résidus Ei chapeau
pour estimer les Ei chapeaux, modèle linéaire classique. Fonction residuals
le -1 est pour enlever l'intercept. on teste les EI chapeau sont un bruit blanc contre les EI chapeaux ne sont pas un bruit blanc : test porte-manteau
```{r}
residuals=lm(as.matrix(Y_2)~X2-1)$residuals
pvalue=whitening_test(residuals)
pvalue
```
Conclusion: 
Lorsqu'on fait le whitening-test pour voir si il y a une dépendance entre les colonnes dans la matrice des résidus on obtient une p-value de 0.79.The p-value est supérieure à 0.05 et donc l'hypothès que chaque ligne de E est un bruit blanc n'est pas rejetée.  
On a envie d'en déduire qu'il n'y a pas de dépendance entre les colonnes et qu'on n'a pas besoin de faire un blanchiement. Toutefois on va quand meme comparer les résultats que l'on obtient sans blanchir et en blanchissant. 


### QUESTION 2.1: ANOVA 1 facteur (temperature): METHODE AVEC BLANCHIEMENT 
On va  blanchir la matrice et estimer le sigma q -1/2 pour pouvoir blanchir les donnnees
puis après on aura une matrice avec des colonnes indépendantes, sur laquelle on pourra faire un lasso
on peut faire lasso. 

### ETAPE BLANCHIEMENT
pour blanchir les données : 3 facons de modéliser la dépendance et d'estimer le sigma chapeau et à chaque fois on refait le test du porte mantean. We try our different covariance modellings for the residuals and see if one manages to remove the dependence among the columns of the residuals matrix by using a Portmanteau test.  
on a envie de vectoriser on considère un Ei tilde et on veut que ce soit du bruit blanc 
(Ecrire ce qu'il a dans H0 et ce qu'on conclut)
```{r}
result=whitening_choice(residuals,c("AR1","nonparam","ARMA"),pAR=1,qMA=1)
result
```

Conclusion:
Le modèle non parametrique a la p-value la plus élevée. On sélectionne ce type de dépendance pour modeliser les residus. On calcule sigma q -1/2 en utilisant le modèle non paramétrique
On récupère les sigma chapeau grace à la fonction whitening (on  stocke juste le sigma chapeau ici avec whitening):  

### ETAPE : sigma q -1/2 
(square root of the inverse of the estimator of the covariance matrix of each row of the residuals matrix)

```{r pressure, echo=FALSE}
square_root_inv_hat_Sigma=whitening(residuals,"nonparam",pAR=1,qMA=0)
```

### ETAPE : selection de variables stability selection
On va appliquer la technique de selection de variable  
On a tout pour blanchir les données comme colonnes indépendantes, on peut les mettre les unes sous les autres = vectoriser. Quand on vectorise Y ronde=XB+E (connaître les tailles et formule de kronecker...).
(alpha = 1 pour lasso. On recupère lamda qui minimise CV, puis on fait stability selection 
(stability selection= on prend vecteur de taile nq et on le coupe en 2 nq/2 observations, on stocke le indices, on lance glmnet avec lasso et lambda de CV on stocke les beta différents de zero. On applique ici stability selection avec 100 replications (il faut faire plutot 500 replicats pour un résultat robuste). 
=> la fonction variable_selection fait tout ça 
il faut choisir un seuil où beta est selectionné à chaque dois 


Cette fonction fournit les fréquences de sélection des variables pour les différents niveaux de la variable qualitative.
```{r pressure, echo=FALSE}
Frequencies=variable_selection(Y_2,X2,square_root_inv_hat_Sigma,nb_repli=100,parallel=FALSE)
Frequencies
```

# ETAPE : Premier plot
On affiche les positions des protéines sélectionnés avec une fréquence supérieure à 95%
On affiche les coefficients sélectionnés dans B.

```{r pressure, echo=FALSE}
install.packages("DescTools")
library(DescTools)
colnames(Frequencies)<-c('Names_of_Y','Names_of_X','frequency')
# Here we can consider the names of Y as numerical since they correspond
# to the ratio m/z of the metabolites.
Frequencies$Names_of_X<-sub('X_df2', '',Frequencies$Names_of_X)
Frequencies$Names_of_Y<-as.numeric(StrRight(gsub('p_AT','',gsub('\\.1$','',Frequencies$Names_of_Y)), 5))
Frequencies
p<-ggplot(data=Frequencies[Frequencies$frequency>=0.95,], aes(x=Names_of_Y,y=Names_of_X,color=frequency))+
geom_tile(size=0.75)+scale_color_gradient2(midpoint=0.95,mid ='orange')+
theme_bw()+ylab('Levels of X')+xlab('m/z')
p
data=Frequencies[Frequencies$frequency>=0.95,]
```


# ETAPE deuxième plot (boulier)
Pour éviter les faux positifs, nous ne considérons que les variables qui sont toujours sélectionnées (avec une
fréquence égale à un)
```{r pressure, echo=FALSE}
p<-ggplot(data=Frequencies[Frequencies$frequency==1,], aes(x=Names_of_Y,y=Names_of_X,color=Names_of_X))+
 geom_point(size=1)+theme_bw()+ylab('Levels of X')+xlab('m/z')
p
```



### QUESTION 3 - ANOVA 1 facteur (imbibition) 

### ETAPE : MATRICE DE DESIGN
On construit la matrice de design 
```{r}
df3= df[df$treatment=="CD_0d", c(5,7:length(df))]
rownames(df3) <- NULL
head(df3)
X_df3=df3[, 1]
X_df3 <- factor(as.character(X_df3))
Y_3 <- as.matrix(df3[,2:length(df3)])
Y_3 <- scale(Y_3)
X3 <- model.matrix(lm(Y_3~ X_df3 + 0))
head(X3)
head(Y_3)


#Dimensions n, p,q
n=nrow(X3)
n
p=ncol(X3)
p
q=dim(Y_3)[2]
q

```


## ETAPE : tester si les colonnes des résidus sont independantes avec le test du Portmanteau test
voir si les colonnes de Y sont indépendantes - estimer les résidus Ei chapeau
pour estimer les Ei chapeaux, modèle linéaire classique. Fonction residuals
le -1 est pour enlever l'intercept. on teste les EI chapeau sont un bruit blanc contre les EI chapeaux ne sont pas un bruit blanc : test porte-manteau
```{r}
residuals=lm(as.matrix(Y_3)~X3-1)$residuals
pvalue=whitening_test(residuals)
pvalue
```
Conclusion: 
Lorsqu'on fait le whitening-test pour voir si il y a une dépendance entre les colonnes dans la matrice des résidus on obtient une p-value de 0.98.The p-value est supérieure à 0.05 et donc l'hypothèse que chaque ligne de E est un bruit blanc n'est pas rejetée.  
On a envie d'en déduire qu'il n'y a pas de dépendance entre les colonnes et qu'on n'a pas besoin de faire un blanchiement. Toutefois on va quand meme comparer les résultats que l'on obtient sans blanchir et en blanchissant. 


### QUESTION 3.1: ANOVA 1 facteur (imbibition): METHODE AVEC BLANCHIEMENT 
On va  blanchir la matrice et estimer le sigma q -1/2 pour pouvoir blanchir les donnnees
puis après on aura une matrice avec des colonnes indépendantes, sur laquelle on pourra faire un lasso
on peut faire lasso. 

### ETAPE BLANCHIEMENT
pour blanchir les données : 3 facons de modéliser la dépendance et d'estimer le sigma chapeau et à chaque fois on refait le test du porte mantean. We try our different covariance modellings for the residuals and see if one manages to remove the dependence among the columns of the residuals matrix by using a Portmanteau test.  
on a envie de vectoriser on considère un Ei tilde et on veut que ce soit du bruit blanc 
(Ecrire ce qu'il a dans H0 et ce qu'on conclut)
```{r}
result=whitening_choice(residuals,c("AR1","nonparam","ARMA"),pAR=1,qMA=1)
result
```

Conclusion:
Le modèle non parametrique a la p-value la plus élevée. On sélectionne ce type de dépendance pour modeliser les residus. On calcule sigma q -1/2 en utilisant le modèle non paramétrique
On récupère les sigma chapeau grace à la fonction whitening (on  stocke juste le sigma chapeau ici avec whitening):  

### ETAPE : sigma q -1/2 
(square root of the inverse of the estimator of the covariance matrix of each row of the residuals matrix)

```{r pressure, echo=FALSE}
square_root_inv_hat_Sigma=whitening(residuals,"nonparam",pAR=1,qMA=0)
```

### ETAPE : selection de variables stability selection
On va appliquer la technique de selection de variable  
On a tout pour blanchir les données comme colonnes indépendantes, on peut les mettre les unes sous les autres = vectoriser. Quand on vectorise Y ronde=XB+E (connaître les tailles et formule de kronecker...).
(alpha = 1 pour lasso. On recupère lamda qui minimise CV, puis on fait stability selection 
(stability selection= on prend vecteur de taile nq et on le coupe en 2 nq/2 observations, on stocke le indices, on lance glmnet avec lasso et lambda de CV on stocke les beta différents de zero. On applique ici stability selection avec 100 replications (il faut faire plutot 500 replicats pour un résultat robuste). 
=> la fonction variable_selection fait tout ça 
il faut choisir un seuil où beta est selectionné à chaque dois 


Cette fonction fournit les fréquences de sélection des variables pour les différents niveaux de la variable qualitative.
```{r pressure, echo=FALSE}
Frequencies=variable_selection(Y_3,X3,square_root_inv_hat_Sigma,nb_repli=100,parallel=FALSE)
Frequencies
```

# ETAPE : Premier plot
On affiche les positions des protéines sélectionnés avec une fréquence supérieure à 95%
On affiche les coefficients sélectionnés dans B.

```{r pressure, echo=FALSE}
install.packages("DescTools")
library(DescTools)
colnames(Frequencies)<-c('Names_of_Y','Names_of_X','frequency')
# Here we can consider the names of Y as numerical since they correspond
# to the ratio m/z of the metabolites.
Frequencies$Names_of_X<-sub('X_df3', '',Frequencies$Names_of_X)
Frequencies$Names_of_Y<-as.numeric(StrRight(gsub('p_AT','',gsub('\\.1$','',Frequencies$Names_of_Y)), 5))
Frequencies
p<-ggplot(data=Frequencies[Frequencies$frequency>=0.95,], aes(x=Names_of_Y,y=Names_of_X,color=frequency))+
geom_tile(size=0.75)+scale_color_gradient2(midpoint=0.95,mid ='orange')+
theme_bw()+ylab('Levels of X')+xlab('m/z')
p
data=Frequencies[Frequencies$frequency>=0.95,]
```


# ETAPE deuxième plot (boulier)
Pour éviter les faux positifs, nous ne considérons que les variables qui sont toujours sélectionnées (avec une
fréquence égale à un)
```{r pressure, echo=FALSE}
p<-ggplot(data=Frequencies[Frequencies$frequency==1,], aes(x=Names_of_Y,y=Names_of_X,color=Names_of_X))+
 geom_point(size=1)+theme_bw()+ylab('Levels of X')+xlab('m/z')
p
```



### QUESTION 4 - ANOVA 2 facteurs (temperature et imbibition) 

### QUESTION 4-1 SANS INTERACTION entre les 2 facteurs 

### ETAPE : MATRICE DE DESIGN
On construit la matrice de design 
```{r}
df4= df[df$treatment=="CD_0d", c(4,5,7:length(df))]
rownames(df4) <- NULL
df4$temp_imb <-paste(df4$temperature, df4$imbibition)
df5=df4[,c(3:length(df4))]
dim(df5)
df6=cbind(df5[,c(length(df5), 1:(length(df5)-1))])
names(df6)
dim(df6)

X_df6=df6[, 1]
X_df6 <- factor(as.character(X_df6))
Y_6 <- as.matrix(df6[,2:length(df6)])
Y_6 <- scale(Y_6)
X6 <- model.matrix(lm(Y_6~ X_df6 + 0))
head(X6)


#Dimensions n, p,q
n=nrow(X6)
n
p=ncol(X6)
p
q=dim(Y_6)[2]
q

```



## ETAPE : tester si les colonnes des résidus sont independantes avec le test du Portmanteau test
voir si les colonnes de Y sont indépendantes - estimer les résidus Ei chapeau
pour estimer les Ei chapeaux, modèle linéaire classique. Fonction residuals
le -1 est pour enlever l'intercept. on teste les EI chapeau sont un bruit blanc contre les EI chapeaux ne sont pas un bruit blanc : test porte-manteau
```{r}
residuals=lm(as.matrix(Y_6)~X6-1)$residuals
pvalue=whitening_test(residuals)
pvalue
```
Conclusion: 
Lorsqu'on fait le whitening-test pour voir si il y a une dépendance entre les colonnes dans la matrice des résidus on obtient une p-value de 0.93.The p-value est supérieure à 0.05 et donc l'hypothès que chaque ligne de E est un bruit blanc n'est pas rejetée.  
On a envie d'en déduire qu'il n'y a pas de dépendance entre les colonnes et qu'on n'a pas besoin de faire un blanchiement. Toutefois on va quand meme comparer les résultats que l'on obtient sans blanchir et en blanchissant. 


### QUESTION : ANOVA 2 facteurs (temperature et imbibition) SANS INTERACTION: METHODE AVEC BLANCHIEMENT 
On va  blanchir la matrice et estimer le sigma q -1/2 pour pouvoir blanchir les donnnees
puis après on aura une matrice avec des colonnes indépendantes, sur laquelle on pourra faire un lasso
on peut faire lasso. 

### ETAPE BLANCHIEMENT
pour blanchir les données : 3 facons de modéliser la dépendance et d'estimer le sigma chapeau et à chaque fois on refait le test du porte mantean. We try our different covariance modellings for the residuals and see if one manages to remove the dependence among the columns of the residuals matrix by using a Portmanteau test.  
on a envie de vectoriser on considère un Ei tilde et on veut que ce soit du bruit blanc 
(Ecrire ce qu'il a dans H0 et ce qu'on conclut)
```{r}
result=whitening_choice(residuals,c("AR1","nonparam","ARMA"),pAR=1,qMA=1)
result
```

Conclusion:
Le modèle non parametrique a la p-value la plus élevée. On sélectionne ce type de dépendance pour modeliser les residus. On calcule sigma q -1/2 en utilisant le modèle non paramétrique
On récupère les sigma chapeau grace à la fonction whitening (on  stocke juste le sigma chapeau ici avec whitening):  

### ETAPE : sigma q -1/2 
(square root of the inverse of the estimator of the covariance matrix of each row of the residuals matrix)

```{r pressure, echo=FALSE}
square_root_inv_hat_Sigma=whitening(residuals,"nonparam",pAR=1,qMA=0)
```

### ETAPE : selection de variables stability selection
On va appliquer la technique de selection de variable  
On a tout pour blanchir les données comme colonnes indépendantes, on peut les mettre les unes sous les autres = vectoriser. Quand on vectorise Y ronde=XB+E (connaître les tailles et formule de kronecker...).
(alpha = 1 pour lasso. On recupère lamda qui minimise CV, puis on fait stability selection 
(stability selection= on prend vecteur de taile nq et on le coupe en 2 nq/2 observations, on stocke le indices, on lance glmnet avec lasso et lambda de CV on stocke les beta différents de zero. On applique ici stability selection avec 100 replications (il faut faire plutot 500 replicats pour un résultat robuste). 
=> la fonction variable_selection fait tout ça 
il faut choisir un seuil où beta est selectionné à chaque dois 


Cette fonction fournit les fréquences de sélection des variables pour les différents niveaux de la variable qualitative.
```{r pressure, echo=FALSE}
Frequencies=variable_selection(Y_6,X6,square_root_inv_hat_Sigma,nb_repli=100,parallel=FALSE)
Frequencies
```

# ETAPE : Premier plot
On affiche les positions des protéines sélectionnés avec une fréquence supérieure à 95%
On affiche les coefficients sélectionnés dans B.

```{r pressure, echo=FALSE}
install.packages("DescTools")
library(DescTools)
colnames(Frequencies)<-c('Names_of_Y','Names_of_X','frequency')
# Here we can consider the names of Y as numerical since they correspond
# to the ratio m/z of the metabolites.
Frequencies$Names_of_X<-sub('X_df6', '',Frequencies$Names_of_X)
Frequencies$Names_of_Y<-as.numeric(StrRight(gsub('p_AT','',gsub('\\.1$','',Frequencies$Names_of_Y)), 5))
Frequencies
p<-ggplot(data=Frequencies[Frequencies$frequency>=0.95,], aes(x=Names_of_Y,y=Names_of_X,color=frequency))+
geom_tile(size=0.75)+scale_color_gradient2(midpoint=0.95,mid ='orange')+
theme_bw()+ylab('Levels of X')+xlab('m/z')
p
data=Frequencies[Frequencies$frequency>=0.95,]
```


# ETAPE deuxième plot (boulier)
Pour éviter les faux positifs, nous ne considérons que les variables qui sont toujours sélectionnées (avec une
fréquence égale à un)
```{r pressure, echo=FALSE}
p<-ggplot(data=Frequencies[Frequencies$frequency==1,], aes(x=Names_of_Y,y=Names_of_X,color=Names_of_X))+
 geom_point(size=1)+theme_bw()+ylab('Levels of X')+xlab('m/z')
p
```




### QUESTION 4-2 AVEC INTERACTION entre les 2 facteurs 

### ETAPE : MATRICE DE DESIGN
On construit la matrice de design 
```{r}
df4= df[df$treatment=="CD_0d", c(4,5,7:length(df))]
rownames(df4) <- NULL
X1_dfint=df4[, 1]
X2_dfint=df4[, 2]
X1_dfint<- factor(as.character(X1_dfint))
X2_dfint<- factor(as.character(X2_dfint))
Y_int <- as.matrix(df4[,3:length(df4)])
Y_int <- scale(Y_int)
Xint <- model.matrix(lm(Y_int~ (X1_dfint:X2_dfint) + 0))
head(Xint)
head(Y_int)

#Dimensions n, p,q
n=nrow(Xint)
n
p=ncol(Xint)
p
q=dim(Y_int)[2]
q

```



## ETAPE : tester si les colonnes des résidus sont independantes avec le test du Portmanteau test
voir si les colonnes de Y sont indépendantes - estimer les résidus Ei chapeau
pour estimer les Ei chapeaux, modèle linéaire classique. Fonction residuals
le -1 est pour enlever l'intercept. on teste les EI chapeau sont un bruit blanc contre les EI chapeaux ne sont pas un bruit blanc : test porte-manteau
```{r}
residuals=lm(as.matrix(Y_int)~Xint-1)$residuals
pvalue=whitening_test(residuals)
pvalue
```

Conclusion: 
Lorsqu'on fait le whitening-test pour voir si il y a une dépendance entre les colonnes dans la matrice des résidus on obtient une p-value de 0.93.The p-value est supérieure à 0.05 et donc l'hypothès que chaque ligne de E est un bruit blanc n'est pas rejetée.  
On a envie d'en déduire qu'il n'y a pas de dépendance entre les colonnes et qu'on n'a pas besoin de faire un blanchiement. Toutefois on va quand meme comparer les résultats que l'on obtient sans blanchir et en blanchissant. 


### QUESTION : ANOVA 2 facteurs (temperature et imbibition) AVEC INTERACTION: METHODE AVEC BLANCHIEMENT 
On va  blanchir la matrice et estimer le sigma q -1/2 pour pouvoir blanchir les donnnees
puis après on aura une matrice avec des colonnes indépendantes, sur laquelle on pourra faire un lasso


### ETAPE BLANCHIEMENT
pour blanchir les données : 3 facons de modéliser la dépendance et d'estimer le sigma chapeau et à chaque fois on refait le test du porte mantean. We try our different covariance modellings for the residuals and see if one manages to remove the dependence among the columns of the residuals matrix by using a Portmanteau test.  
on a envie de vectoriser on considère un Ei tilde et on veut que ce soit du bruit blanc 
(Ecrire ce qu'il a dans H0 et ce qu'on conclut)
```{r}
result=whitening_choice(residuals,c("AR1","nonparam","ARMA"),pAR=1,qMA=1)
result
```

### ETAPE : sigma q -1/2 
(square root of the inverse of the estimator of the covariance matrix of each row of the residuals matrix)

```{r pressure, echo=FALSE}
square_root_inv_hat_Sigma=whitening(residuals,"nonparam",pAR=1,qMA=0)
```

### ETAPE : selection de variables stability selection
On va appliquer la technique de selection de variable  
On a tout pour blanchir les données comme colonnes indépendantes, on peut les mettre les unes sous les autres = vectoriser. Quand on vectorise Y ronde=XB+E (connaître les tailles et formule de kronecker...).
(alpha = 1 pour lasso. On recupère lamda qui minimise CV, puis on fait stability selection 
(stability selection= on prend vecteur de taile nq et on le coupe en 2 nq/2 observations, on stocke le indices, on lance glmnet avec lasso et lambda de CV on stocke les beta différents de zero. On applique ici stability selection avec 100 replications (il faut faire plutot 500 replicats pour un résultat robuste). 
=> la fonction variable_selection fait tout ça 
il faut choisir un seuil où beta est selectionné à chaque dois 


Cette fonction fournit les fréquences de sélection des variables pour les différents niveaux de la variable qualitative.
```{r pressure, echo=FALSE}
Frequencies=variable_selection(Y_int,Xint,square_root_inv_hat_Sigma,nb_repli=100,parallel=FALSE)
Frequencies
```
# ETAPE : Premier plot
On affiche les positions des protéines sélectionnés avec une fréquence supérieure à 95%
On affiche les coefficients sélectionnés dans B.

```{r pressure, echo=FALSE}
install.packages("DescTools")
library(DescTools)
colnames(Frequencies)<-c('Names_of_Y','Names_of_X','frequency')
# Here we can consider the names of Y as numerical since they correspond
# to the ratio m/z of the metabolites.
Frequencies$Names_of_X<-sub('X1_dfint', '', sub('X2_dfint', '',Frequencies$Names_of_X))
Frequencies$Names_of_Y<-as.numeric(StrRight(gsub('p_AT','',gsub('\\.1$','',Frequencies$Names_of_Y)), 5))
Frequencies
p<-ggplot(data=Frequencies[Frequencies$frequency>=0.95,], aes(x=Names_of_Y,y=Names_of_X,color=frequency))+
geom_tile(size=0.75)+scale_color_gradient2(midpoint=0.95,mid ='orange')+
theme_bw()+ylab('Levels of X')+xlab('m/z')
p
data=Frequencies[Frequencies$frequency>=0.95,]
```


# ETAPE deuxième plot (boulier)
Pour éviter les faux positifs, nous ne considérons que les variables qui sont toujours sélectionnées (avec une
fréquence égale à un)
```{r pressure, echo=FALSE}
p<-ggplot(data=Frequencies[Frequencies$frequency==1,], aes(x=Names_of_Y,y=Names_of_X,color=Names_of_X))+
 geom_point(size=1)+theme_bw()+ylab('Levels of X')+xlab('m/z')
p
```